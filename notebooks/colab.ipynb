{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "All rights reserved.\n",
    "This source code is licensed under the license found in the\n",
    "LICENSE file in the sav_dataset directory of this source tree.\n",
    "\n",
    "# Video Seal Inference\n",
    "\n",
    "[[`arXiv`](https://arxiv.org/abs/2412.09492)]\n",
    "[[`Colab`](https://colab.research.google.com/github/facebookresearch/videoseal/blob/main/notebooks/colab.ipynb)]\n",
    "[[`Demo`](https://aidemos.meta.com/videoseal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone repository and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/facebookresearch/videoseal.git\n",
    "%cd videoseal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install/upgrade ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade ffmpeg-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/videoseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import logging\n",
    "logging.getLogger(\"matplotlib.image\").setLevel(logging.ERROR)\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import os\n",
    "import cv2\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "\n",
    "from videoseal.evals.metrics import bit_accuracy\n",
    "from videoseal.models import Videoseal\n",
    "\n",
    "\n",
    "def get_video_info(input_path):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    codec = int(video.get(cv2.CAP_PROP_FOURCC))\n",
    "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Decode codec to human-readable form\n",
    "    codec_str = \"\".join([chr((codec >> 8 * i) & 0xFF) for i in range(4)])\n",
    "    \n",
    "    video.release()  # Close the video file\n",
    "\n",
    "    return {\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"fps\": fps,\n",
    "        \"codec\": codec_str,\n",
    "        \"num_frames\": num_frames\n",
    "    }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model\n",
    "\n",
    "The videoseal library provides pretrained models for embedding and extracting watermarks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VideoSeal model\n",
    "import videoseal\n",
    "model = videoseal.load(\"videoseal\")\n",
    "\n",
    "# Set the model to evaluation mode and move it to the selected device\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "The embedding process is the process of hiding the watermark in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_video_clip(\n",
    "    model: Videoseal,\n",
    "    clip: np.ndarray,\n",
    "    msgs: torch.Tensor\n",
    ") -> np.ndarray:\n",
    "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "    outputs = model.embed(clip_tensor, msgs=msgs, is_video=True)\n",
    "    processed_clip = outputs[\"imgs_w\"]\n",
    "    processed_clip = (processed_clip * 255.0).byte().permute(0, 2, 3, 1).numpy()\n",
    "    return processed_clip\n",
    "\n",
    "def embed_video(\n",
    "    model: Videoseal,\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    chunk_size: int,\n",
    "    crf: int = 23\n",
    ") -> None:\n",
    "    # Read video dimensions\n",
    "    video_info = get_video_info(input_path)\n",
    "    width = int(video_info['width'])\n",
    "    height = int(video_info['height'])\n",
    "    fps = float(video_info['fps'])\n",
    "    codec = video_info['codec']\n",
    "    num_frames = int(video_info['num_frames'])\n",
    "\n",
    "    # Open the input video\n",
    "    process1 = (\n",
    "        ffmpeg\n",
    "        .input(input_path)\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
    "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
    "    )\n",
    "    # Open the output video\n",
    "    process2 = (\n",
    "        ffmpeg\n",
    "        .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
    "        .output(output_path, vcodec='libx264', pix_fmt='yuv420p', r=fps, crf=crf)\n",
    "        .overwrite_output()\n",
    "        .run_async(pipe_stdin=True, pipe_stderr=subprocess.PIPE)\n",
    "    )\n",
    "    \n",
    "    # Create a random message\n",
    "    msgs = model.get_random_msg()\n",
    "    with open(output_path.replace(\".mp4\", \".txt\"), \"w\") as f:\n",
    "        f.write(\"\".join([str(msg.item()) for msg in msgs[0]]))\n",
    "\n",
    "    # Process the video\n",
    "    frame_size = width * height * 3\n",
    "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
    "    frame_count = 0\n",
    "    pbar = tqdm(total=num_frames, desc=\"Watermark embedding\")\n",
    "    while True:\n",
    "        in_bytes = process1.stdout.read(frame_size)\n",
    "        if not in_bytes:\n",
    "            break\n",
    "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
    "        chunk[frame_count % chunk_size] = frame\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "        if frame_count % chunk_size == 0:\n",
    "            processed_frame = embed_video_clip(model, chunk, msgs)\n",
    "            process2.stdin.write(processed_frame.tobytes())\n",
    "    process1.stdout.close()\n",
    "    process2.stdin.close()\n",
    "    process1.wait()\n",
    "    process2.wait()\n",
    "\n",
    "    return msgs\n",
    "\n",
    "# Path to the input video\n",
    "video_path = \"./assets/videos/1.mp4\"\n",
    "\n",
    "# Create the output directory and path\n",
    "output_dir = \"./outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, os.path.basename(video_path))\n",
    "\n",
    "# Embed the video\n",
    "msgs_ori = embed_video(model, video_path, output_path, 16)\n",
    "print(f\"Saved watermarked video to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "\n",
    "Load the video output from the embedding process and extract the watermark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video_clip(\n",
    "    model: Videoseal,\n",
    "    clip: np.ndarray\n",
    ") -> torch.Tensor:\n",
    "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
    "    outputs = model.detect(clip_tensor, is_video=True)\n",
    "    output_bits = outputs[\"preds\"][:, 1:]  # exclude the first which may be used for detection\n",
    "    return output_bits\n",
    "\n",
    "def detect_video(\n",
    "    model: Videoseal,\n",
    "    input_path: str,\n",
    "    chunk_size: int\n",
    ") -> None:\n",
    "    # Read video dimensions\n",
    "    video_info = get_video_info(input_path)\n",
    "    width = int(video_info['width'])\n",
    "    height = int(video_info['height'])\n",
    "    num_frames = int(video_info['num_frames'])\n",
    "\n",
    "    # Open the input video\n",
    "    process1 = (\n",
    "        ffmpeg\n",
    "        .input(input_path)\n",
    "        .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
    "    )\n",
    "    \n",
    "    # Process the video\n",
    "    frame_size = width * height * 3\n",
    "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
    "    frame_count = 0\n",
    "    soft_msgs = []\n",
    "    pbar = tqdm.tqdm(total=num_frames, desc=\"Watermark extraction\")\n",
    "    while True:\n",
    "        in_bytes = process1.stdout.read(frame_size)\n",
    "        if not in_bytes:\n",
    "            break\n",
    "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
    "        chunk[frame_count % chunk_size] = frame\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "        if frame_count % chunk_size == 0:\n",
    "            soft_msgs.append(detect_video_clip(model, chunk))\n",
    "    process1.stdout.close()\n",
    "    process1.wait()\n",
    "\n",
    "    soft_msgs = torch.cat(soft_msgs, dim=0)\n",
    "    soft_msgs = soft_msgs.mean(dim=0)  # Average the predictions across all frames\n",
    "    return soft_msgs\n",
    "\n",
    "# Detect the watermark\n",
    "soft_msgs = detect_video(model, output_path, 16)\n",
    "bit_acc = bit_accuracy(soft_msgs, msgs_ori).item() * 100\n",
    "print(f\"Binary message extracted with {bit_acc:.1f}% bit accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
